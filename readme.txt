Team number: xohw21-204
Project name: GEM: Gradient Enabled Mutual-Information
Link to YouTube Video(s): https://youtu.be/py9bzGb1bHY
Link to project repository: https://github.com/luigifusco/GEM-XOHW-2021

University name: Politecnico di Milano
Participant(s): Luigi Fusco, Eleonora D'Arnese
Email: luigi1.fusco@mail.polimi.it, eleonora.darnese@polimi.it
Supervisor name: Marco Santambrogio
Supervisor e-mail: marco.santambrogio@polimi.it

Board used: zcu104
Software Version: Vivado 2019.2
Brief description of project:
The project consists in the implementation of two customizable accelerators for the computation of mutual information and its gradient applied to images.
 

Description of archive (explain directory structure, documents and source files):
framework - folder containing python and C++ code constituting a small image registration framework
metrics - folder containing three different subfolders, each containing the source of a different accelerator
scripts - scripts used by the gen_all.sh file
benchmark.ipynb - jupyter notebook containing all benchmarks
demo.ipynb - jupyter notebook containing the demo showed in the video presentation
gen_all.sh - script used to generate the bitstreams
IM10_x.dcm - images used in the demo
README.md - main readme file, showed in the homepage of the repository
 

Instructions to build and test project

The registration framework is written in python3 and expects the following libraries to be installed: `numpy, matplotlib, scipy, opencv-python, pydicom, jupyter, ctypes`

## The Zip
A) The submitted zip file contains the folder `gem`. The folder can be transferred to a ZCU104 board connected to the network with the command:
```
rsync -avz <board_username>@<board_ip>:~/jupyter_notebooks/ gem/
```
The `gem` folder already contains the compiled files and the bitstreams ready to be used.

A.bis) Install from scratch

0. Be sure to have Vivado in path (e.g., `source <path_to_vivado>/settings64.sh` )

1. The bitstreams can be generated by running the `gen_all.sh` script. This should create the `build/assets` subfolder, containing one subfolder for each accelerator. `mutual_information` contains the mutual information accelerator, `mutual_information_gradient` contains the mutual information gradient accelerator in the version outputting the gradient of mutual information with respect to the pixels, and `mutual_information_gradient_matrix` contains the mutual information gradient accelerator in the version outputting the *gradient matrix* for performing the lookup in software. Even though the sources for the last two differ only by one macro definition, they are built as different accelerators in order to make it more straight forward to run the benchmarks.

2. At this point the folder containing the whole repository should be moved to the target board. The C++ files containing the reference SW implementations can now be compiled. This can be done by navigating to the framework folder and running `make`.

B) [optional] Customize
The sources for the accelerators are found in the `metrics` folder. The configuration files are `<folder_name>.hpp` for the gradient accelerators and `parzen.hpp` for the mutual information accelerator.

### mutual_information
The number of processing elements can be modified by changing the number at line `47`. All powers of 2 up to 64 can be used.

### mutual_infromation_gradient and mutual_information_gradient_matrix
`mutual_information_gradient` and `mutual_information_gradient_matrix` differ only by a macro definition. The data type used to perform fractions and logarithms can be changed to fixed point by commenting out line `34`. The number of processing elements can be modified by changing the number at line `35`. All powers of 2 up to 64 can be used.


C) Run

The demo seen in the presentation video can be run by executing `jupyter notebook` in the main directory and opening and running the `demo.ipynb` notebook.

The full suite of benchmarks is found in the `benchmark.ipynb` notebook.