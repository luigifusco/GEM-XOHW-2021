# GEM-XOHW-2021

This is the official public repository of the project "GEM: Gradient Enabled Mutual information", by Luigi Fusco (luigi1.fusco@mail.polimi.it) and Eleonora D'Arnese (eleonora.darnese@polimi.it), supervised by Prof. Marco D. Santambrogio (marco.santambrogio@polimi.it).

This repository contains the source code for the accelerators, jupyter notebooks containing demos, and a small registration framework built for demonstration purposes.
Everything has been tested on a ZCU104 Evaluation Kit.

## Software versions

```
Vivado: 2019.2
Vivado HLS: 2019.2
Python: 3.x.x
```
The registration framework is written in python3 and expects the following libraries to be installed: `numpy, matplotlib, scipy, opencv-python, pydicom, jupyter, ctypes`

## The Zip
The submitted zip file contains the folder `gem`. The folder can be transferred to a ZCU104 board connected to the network with the command:
```
rsync -avz <board_username>@<board_ip>:~/jupyter_notebooks/ gem/
```
The `gem` folder already contains the compiled files and the bitstreams ready to be used.

## Install from scratch

0. Be sure to have Vivado in path (e.g., `source <path_to_vivado>/settings64.sh` )

1. The bitstreams can be generated by running the `gen_all.sh` script. This should create the `build/assets` subfolder, containing one subfolder for each accelerator. `mutual_information` contains the mutual information accelerator, `mutual_information_gradient` contains the mutual information gradient accelerator in the version outputting the gradient of mutual information with respect to the pixels, and `mutual_information_gradient_matrix` contains the mutual information gradient accelerator in the version outputting the *gradient matrix* for performing the lookup in software. Even though the sources for the last two differ only by one macro definition, they are built as different accelerators in order to make it more straight forward to run the benchmarks.

2. At this point the folder containing the whole repository should be moved to the target board. The C++ files containing the reference SW implementations can now be compiled. This can be done by navigating to the framework folder and running `make`.

## Customize
The sources for the accelerators are found in the `metrics` folder. The configuration files are `<folder_name>.hpp` for the gradient accelerators and `parzen.hpp` for the mutual information accelerator.

### mutual_information
The number of processing elements can be modified by changing the number at line `47`. All powers of 2 up to 64 can be used.

### mutual_information_gradient and mutual_information_gradient_matrix
`mutual_information_gradient` and `mutual_information_gradient_matrix` differ only by a macro definition. The data type used to perform fractions and logarithms can be changed to fixed point by commenting out line `34`. The number of processing elements can be modified by changing the number at line `35`. All powers of 2 up to 64 can be used.
## Run

The demo seen in the presentation video can be run by executing `jupyter notebook` in the main directory and opening and running the `demo.ipynb` notebook.

The full suite of benchmarks is found in the `benchmark.ipynb` notebook.